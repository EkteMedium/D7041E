{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project\n",
    "This is the main mini-project notebook handeling pre-processing, model definition, training, and evalutaion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "The first cell block handels some necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Generic dataset proceessing class.\n",
    "from Project.generic_dataset import GenericDataset\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def run_kmeans_random_on_ds(ds,*,validation = False, **kwargs):\n",
    "\n",
    "    # Get training data.\n",
    "    (X_train,L_train) = ds.get_train()\n",
    "\n",
    "    # Fit data.\n",
    "    kmeans = KMeans(n_clusters=ds.get_metadata()[\"num_classes\"], random_state=0, n_init=\"auto\", init=\"random\").fit(X_train)\n",
    "\n",
    "    # Find which training label is most correlated to which cluster.\n",
    "    correlation_matrix = np.zeros((ds.get_metadata()[\"num_classes\"],ds.get_metadata()[\"num_classes\"]))\n",
    "    for cluster, label in zip(list(kmeans.labels_),list(L_train)):\n",
    "        correlation_matrix[cluster,label] += 1\n",
    "\n",
    "    cluster2label = np.argmax(correlation_matrix,axis=1)\n",
    "\n",
    "    # Fetch Test/Validation set.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "\n",
    "    # Get predictions.\n",
    "    predicted_cluster = kmeans.predict(X_test)\n",
    "    L_pred = cluster2label[predicted_cluster]\n",
    "\n",
    "    # Return accuracy.\n",
    "    return ((sum(L_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def run_kmeans_on_ds(ds,*,validation = False, **kwargs):\n",
    "\n",
    "    # Get training data.\n",
    "    (X_train,L_train) = ds.get_train()\n",
    "\n",
    "    # Fit data.\n",
    "    kmeans = KMeans(n_clusters=ds.get_metadata()[\"num_classes\"], n_init=\"auto\").fit(X_train)\n",
    "\n",
    "    # Find which training label is most correlated to which cluster.\n",
    "    correlation_matrix = np.zeros((ds.get_metadata()[\"num_classes\"],ds.get_metadata()[\"num_classes\"]))\n",
    "    for cluster, label in zip(list(kmeans.labels_),list(L_train)):\n",
    "        correlation_matrix[cluster,label] += 1\n",
    "\n",
    "    cluster2label = np.argmax(correlation_matrix,axis=1)\n",
    "\n",
    "    # Fetch Test/Validation set.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    \n",
    "    # Get predictions.\n",
    "    predicted_cluster = kmeans.predict(X_test)\n",
    "    L_pred = cluster2label[predicted_cluster]\n",
    "\n",
    "    # Return accuracy.\n",
    "    return ((sum(L_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "def run_birch_on_ds(ds,branching_factor=50, threshold=0.5,*,validation = False, **kwargs):\n",
    "\n",
    "    # Get training data.\n",
    "    (X_train,L_train) = ds.get_train()\n",
    "\n",
    "    # Fit data.\n",
    "    birch = Birch(n_clusters=ds.get_metadata()[\"num_classes\"], branching_factor=branching_factor, threshold=threshold).fit(X_train)\n",
    "\n",
    "    # Find which training label is most correlated to which cluster.\n",
    "    correlation_matrix = np.zeros((len(np.unique(birch.labels_)),ds.get_metadata()[\"num_classes\"]))\n",
    "    for cluster, label in zip(list(birch.labels_),list(L_train)):\n",
    "        correlation_matrix[cluster,label] += 1\n",
    "\n",
    "    cluster2label = np.argmax(correlation_matrix,axis=1)\n",
    "\n",
    "    # Fetch Test/Validation set.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    \n",
    "    # Get predictions.\n",
    "    predicted_cluster = birch.predict(X_test)\n",
    "    L_pred = cluster2label[predicted_cluster]\n",
    "\n",
    "    # Return accuracy.\n",
    "    return ((sum(L_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ANN\n",
    "def run_ann_on_ds(ds,seed=0,nepochs=20,batch_size=3,learning_rate=0.05,layer_configuration=[100,100],*,validation = False, **kwargs):\n",
    "    \n",
    "    # Get training data, validation data, and test data. (if validation is true the validation set is used for evaluation)\n",
    "    (X_train, L_train) = ds.get_train()\n",
    "    (X_val, L_val) = ds.get_val()\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "\n",
    "    # Get train and validation batches.\n",
    "    train_data, train_labels, valid_data, valid_labels=ANN.prepare_for_backprop(batch_size, X_train, L_train, X_val, L_val, nclasses=ds.get_metadata()[\"num_classes\"])\n",
    "\n",
    "    # Find MLP with highest validation accuracy to avoid overfitting. (Early stopping)\n",
    "    mlp = ANN.MultiLayerPerceptron(layer_config=[ds.get_metadata()[\"num_features\"]] + layer_configuration + [ds.get_metadata()[\"num_classes\"]], batch_size=batch_size,seed=seed)\n",
    "    best_mlp = mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=False, eval_test=False, num_epochs=nepochs, eta=learning_rate)\n",
    "\n",
    "    # Get test bathces.\n",
    "    test_data, test_labels = ANN.create_batches(X_test, L_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              create_bit_vector=True,\n",
    "                                              nclasses=ds.get_metadata()[\"num_classes\"])\n",
    "\n",
    "    # Return accuracy of test batches on the best MLP.\n",
    "    return best_mlp.get_accuracy(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import som\n",
    "def run_som_on_ds(ds,ndim=16,nepochs=10,*,validation = False, **kwargs):\n",
    "    \n",
    "    # Get training data.\n",
    "    (X_train, L_train) = ds.get_train()\n",
    "    L_train = list(L_train)\n",
    "\n",
    "    # Get test data.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    L_test = list(L_test)\n",
    "\n",
    "    # Train a som.\n",
    "    trained_som = som.SOM(X_train,nepochs=nepochs,ndim=ndim)\n",
    "\n",
    "    # Get confusion matrix on test set and get accuracy.\n",
    "    _, conf = som.SOM_Test(trained_som,X_train,L_train,X_test,L_test,ds.get_metadata()[\"num_classes\"],ndim=ndim)\n",
    "    accuracy = (np.sum(np.eye(conf.shape[0])*conf)/np.sum(conf)).item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def run_svm_on_ds(ds,kernel='rbf',*,validation = False, **kwargs):\n",
    "    \n",
    "    # Get training data.\n",
    "    (X,Y) = ds.get_train()\n",
    "    \n",
    "    # Fit training data.\n",
    "    clf = SVC(kernel=kernel).fit(X,Y)\n",
    "    \n",
    "    # Get test data.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    \n",
    "    # Get predictions and return accuracy.\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return (sum(Y_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def run_knn_on_ds(ds,n_neighbors=5,weights='uniform',*,validation = False, **kwargs):\n",
    "    \n",
    "    # Get training data.\n",
    "    (X,Y) = ds.get_train()\n",
    "    \n",
    "    # Fit training data.\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights).fit(X,Y)\n",
    "    \n",
    "    # Get test data.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    \n",
    "    # Get predictions and return accuracy.\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return (sum(Y_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def run_random_forest_on_ds(ds,n_estimators=100,max_depth=None,*,validation = False, **kwargs):\n",
    "\n",
    "    # Get training data.\n",
    "    (X_train,L_train) = ds.get_train()\n",
    "    \n",
    "    # Fit training data.\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth).fit(X_train,L_train)\n",
    "    \n",
    "    # Get test data.\n",
    "    if validation:\n",
    "        (X_test,L_test) = ds.get_val()\n",
    "    else:\n",
    "        (X_test,L_test) = ds.get_test()\n",
    "    \n",
    "    # Get predictions and return accuracy.\n",
    "    L_pred = clf.predict(X_test)\n",
    "    return (sum(L_pred.squeeze()==L_test.squeeze())/L_test.squeeze().shape)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def validate(ds,func,seeds, display_bar = True,**kwargs):\n",
    "    '''\n",
    "        Runs model with multiple hyperparameters multiple times and finds the best parameters. And evaluates on the test set.\n",
    "    Args:\n",
    "        ds: Dataset to evaluate on.\n",
    "        func: Function that returns accuracy for a certain model.\n",
    "        seeds: Which seeds to use for evalutaion\n",
    "        **kwargs: Dictionary with hyperparameters and list of values to run. \n",
    "    Return:\n",
    "        accuracy: Returns the accuracy.\n",
    "        best_kwargs: Returns the parameters with best accuracy.\n",
    "    '''\n",
    "\n",
    "\n",
    "    keys = list(kwargs.keys())\n",
    "    indexes = [0]*len(keys)\n",
    "\n",
    "    # Gets total number of permutations.\n",
    "    prod = 1\n",
    "    for e in [len(l) for l in list(kwargs.values())]:\n",
    "        prod *= e\n",
    "    if display_bar:\n",
    "        bar = tqdm(total=prod)\n",
    "\n",
    "    # Init best parameters.\n",
    "    best_accuracy = 0\n",
    "    best_time = float('inf')\n",
    "    best_kwargs = {}\n",
    "\n",
    "    while True:\n",
    "        # Get permutation to try.\n",
    "        new_kwargs = dict([(key,kwargs[key][index]) for key,index in zip(keys,indexes)])\n",
    "\n",
    "        # Average the accuracy over 3 runs.\n",
    "        t1 = perf_counter()\n",
    "        sum_accuracy = 0\n",
    "        samples_for_val = 3\n",
    "        for seed in seeds[:samples_for_val]:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            new_kwargs['seed']=seed\n",
    "            try:\n",
    "                sum_accuracy += func(ds,**new_kwargs, validation = True)\n",
    "            except ValueError as e:\n",
    "                print(\"Value error in function,excluding from average: \", str(e))\n",
    "        \n",
    "\n",
    "        time = (perf_counter()-t1)/samples_for_val\n",
    "        accuracy = sum_accuracy/samples_for_val\n",
    "\n",
    "        # Update best if current accuracy is better than best, if equal take model with least time.\n",
    "        if accuracy>best_accuracy: #or (accuracy==best_accuracy and time<best_time):\n",
    "            best_accuracy=accuracy\n",
    "            best_time=time\n",
    "            best_kwargs = new_kwargs\n",
    "\n",
    "        # Update progressbar.\n",
    "        if display_bar:\n",
    "            bar.update(1)\n",
    "\n",
    "        # Break if no premutations.\n",
    "        if len(indexes)==0:\n",
    "            break\n",
    "        \n",
    "        # Increase index array in right way.\n",
    "        indexes[0]+=1\n",
    "        for i in range(len(indexes)-1):\n",
    "            if indexes[i]>=len(kwargs[keys[i]]):\n",
    "                indexes[i]=0\n",
    "                indexes[i+1] += 1\n",
    "        # Break loop when finished.\n",
    "        if indexes[-1]>=len(kwargs[keys[-1]]):\n",
    "            break\n",
    "    \n",
    "    # Average accuracies on best kwargs, for the test set.\n",
    "    sum_accuracy = 0\n",
    "    for seed in seeds:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        try:\n",
    "            sum_accuracy += func(ds,**best_kwargs, validation = False)\n",
    "        except ValueError as e:\n",
    "            print(\"Value error in function,excluding from average: \", str(e))\n",
    "    accuracy = sum_accuracy/len(seeds)\n",
    "        \n",
    "    return accuracy, best_kwargs, best_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datasets: 77\n",
      "\n",
      "id: 12\n",
      "name: Balance Scale \t num_instances: 625 \t num_classes: 3 \t num_features: 4\n",
      "SVM: 94.4%\tSOM: 73.6%\tANN: 95.0%\tKMEANS: 66.4%\tKMEANS_RANDOM: 72.0%\tBIRCH: 64.8%\tRFC: 92.2%\tKNN: 92.8%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 94.4%\n",
      "Average accuracy RFC: 92.2%\n",
      "Average accuracy KNN: 92.8%\n",
      "Average accuracy ANN: 95.0%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 73.6%\n",
      "Average accuracy KMEANS: 66.4%\n",
      "Average accuracy KMEANS_RANDOM: 72.0%\n",
      "Average accuracy BIRCH: 64.8%\n",
      "\n",
      "id: 14\n",
      "name: Breast Cancer \t num_instances: 286 \t num_classes: 2 \t num_features: 39\n",
      "SVM: 77.6%\tSOM: 77.6%\tANN: 75.0%\tKMEANS: 75.9%\tKMEANS_RANDOM: 75.9%\tBIRCH: 75.9%\tRFC: 79.7%\tKNN: 75.9%\n",
      "\n",
      "id: 15\n",
      "name: Breast Cancer Wisconsin (Original) \t num_instances: 699 \t num_classes: 3 \t num_features: 9\n",
      "SVM: 96.4%\tSOM: 96.4%\tANN: 97.0%\tKMEANS: 97.1%\tKMEANS_RANDOM: 97.1%\tBIRCH: 95.6%\tRFC: 96.4%\tKNN: 97.1%\n",
      "\n",
      "id: 16\n",
      "name: Breast Cancer Wisconsin (Prognostic) \t num_instances: 198 \t num_classes: 2 \t num_features: 33\n",
      "SVM: 76.9%\tSOM: 79.5%\tANN: 80.0%\tKMEANS: 82.1%\tKMEANS_RANDOM: 82.1%\tBIRCH: 82.1%\tRFC: 81.0%\tKNN: 76.9%\n",
      "\n",
      "id: 17\n",
      "name: Breast Cancer Wisconsin (Diagnostic) \t num_instances: 569 \t num_classes: 2 \t num_features: 30\n",
      "SVM: 94.7%\tSOM: 87.7%\tANN: 94.5%\tKMEANS: 88.1%\tKMEANS_RANDOM: 88.6%\tBIRCH: 84.2%\tRFC: 90.5%\tKNN: 93.0%\n",
      "\n",
      "id: 19\n",
      "name: Car Evaluation \t num_instances: 1728 \t num_classes: 4 \t num_features: 21\n",
      "SVM: 96.8%\tSOM: 73.4%\tANN: 95.6%\tKMEANS: 67.9%\tKMEANS_RANDOM: 67.9%\tBIRCH: 67.9%\tRFC: 92.4%\tKNN: 84.7%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 89.5%\n",
      "Average accuracy RFC: 88.7%\n",
      "Average accuracy KNN: 86.7%\n",
      "Average accuracy ANN: 89.5%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 81.4%\n",
      "Average accuracy KMEANS: 79.6%\n",
      "Average accuracy KMEANS_RANDOM: 80.6%\n",
      "Average accuracy BIRCH: 78.4%\n",
      "\n",
      "id: 22\n",
      "name: Chess (King-Rook vs. King-Pawn) \t num_instances: 3196 \t num_classes: 2 \t num_features: 71\n",
      "SVM: 97.5%\tSOM: 60.9%\tANN: 96.7%\tKMEANS: 51.1%\tKMEANS_RANDOM: 51.1%\tBIRCH: 60.6%\tRFC: 97.6%\tKNN: 92.2%\n",
      "\n",
      "id: 27\n",
      "name: Credit Approval \t num_instances: 690 \t num_classes: 2 \t num_features: 46\n",
      "SVM: 91.8%\tSOM: 76.1%\tANN: 91.5%\tKMEANS: 67.2%\tKMEANS_RANDOM: 64.2%\tBIRCH: 61.9%\tRFC: 90.1%\tKNN: 88.1%\n",
      "\n",
      "id: 28\n",
      "name: Japanese Credit Screening \t num_instances: 125 \t num_classes: 2 \t num_features: 570\n",
      "SVM: 87.0%\tSOM: 80.4%\tANN: 88.5%\tKMEANS: 77.5%\tKMEANS_RANDOM: 76.8%\tBIRCH: 79.7%\tRFC: 89.6%\tKNN: 87.7%\n",
      "\n",
      "id: 30\n",
      "name: Contraceptive Method Choice \t num_instances: 1473 \t num_classes: 3 \t num_features: 9\n",
      "SVM: 54.9%\tSOM: 43.1%\tANN: 53.7%\tKMEANS: 43.2%\tKMEANS_RANDOM: 44.4%\tBIRCH: 48.1%\tRFC: 56.7%\tKNN: 49.8%\n",
      "\n",
      "id: 32\n",
      "name: Cylinder Bands \t num_instances: 512 \t num_classes: 3 \t num_features: 914\n",
      "SVM: 68.9%\tSOM: 55.4%\tANN: 65.7%\tKMEANS: 63.8%\tKMEANS_RANDOM: 63.5%\tBIRCH: 67.6%\tRFC: 72.4%\tKNN: 74.3%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 85.2%\n",
      "Average accuracy RFC: 85.3%\n",
      "Average accuracy KNN: 82.9%\n",
      "Average accuracy ANN: 84.8%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 73.1%\n",
      "Average accuracy KMEANS: 70.9%\n",
      "Average accuracy KMEANS_RANDOM: 71.2%\n",
      "Average accuracy BIRCH: 71.7%\n",
      "\n",
      "id: 33\n",
      "name: Dermatology \t num_instances: 366 \t num_classes: 6 \t num_features: 34\n",
      "SVM: 95.8%\tSOM: 76.4%\tANN: 97.1%\tKMEANS: 80.6%\tKMEANS_RANDOM: 80.6%\tBIRCH: 80.6%\tRFC: 95.3%\tKNN: 93.1%\n",
      "\n",
      "id: 39\n",
      "name: Ecoli \t num_instances: 336 \t num_classes: 8 \t num_features: 7\n",
      "SVM: 88.2%\tSOM: 76.5%\tANN: 84.1%\tKMEANS: 82.6%\tKMEANS_RANDOM: 79.4%\tBIRCH: 72.1%\tRFC: 84.4%\tKNN: 85.3%\n",
      "\n",
      "id: 42\n",
      "name: Glass Identification \t num_instances: 214 \t num_classes: 7 \t num_features: 9\n",
      "SVM: 69.8%\tSOM: 58.1%\tANN: 45.2%\tKMEANS: 44.7%\tKMEANS_RANDOM: 44.2%\tBIRCH: 44.2%\tRFC: 76.3%\tKNN: 60.5%\n",
      "\n",
      "id: 43\n",
      "name: Haberman's Survival \t num_instances: 306 \t num_classes: 2 \t num_features: 3\n",
      "SVM: 66.1%\tSOM: 67.7%\tANN: 66.7%\tKMEANS: 66.1%\tKMEANS_RANDOM: 66.1%\tBIRCH: 69.4%\tRFC: 68.4%\tKNN: 67.7%\n",
      "\n",
      "id: 44\n",
      "name: Hayes-Roth \t num_instances: 160 \t num_classes: 3 \t num_features: 4\n",
      "SVM: 44.4%\tSOM: 55.6%\tANN: 38.1%\tKMEANS: 38.5%\tKMEANS_RANDOM: 29.6%\tBIRCH: 40.7%\tRFC: 60.0%\tKNN: 55.6%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.3%\n",
      "Average accuracy RFC: 82.7%\n",
      "Average accuracy KNN: 79.7%\n",
      "Average accuracy ANN: 79.0%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 71.1%\n",
      "Average accuracy KMEANS: 68.3%\n",
      "Average accuracy KMEANS_RANDOM: 67.7%\n",
      "Average accuracy BIRCH: 68.5%\n",
      "\n",
      "id: 45\n",
      "name: Heart Disease \t num_instances: 303 \t num_classes: 5 \t num_features: 13\n",
      "SVM: 51.7%\tSOM: 51.7%\tANN: 58.9%\tKMEANS: 54.7%\tKMEANS_RANDOM: 50.0%\tBIRCH: 53.3%\tRFC: 55.0%\tKNN: 53.3%\n",
      "\n",
      "id: 50\n",
      "name: Image Segmentation \t num_instances: 2310 \t num_classes: 7 \t num_features: 19\n",
      "SVM: 78.6%\tSOM: 59.5%\tANN: 85.0%\tKMEANS: 58.6%\tKMEANS_RANDOM: 66.7%\tBIRCH: 66.7%\tRFC: 90.5%\tKNN: 76.2%\n",
      "\n",
      "id: 52\n",
      "name: Ionosphere \t num_instances: 351 \t num_classes: 2 \t num_features: 34\n",
      "SVM: 97.2%\tSOM: 77.5%\tANN: 87.1%\tKMEANS: 74.6%\tKMEANS_RANDOM: 73.2%\tBIRCH: 74.6%\tRFC: 96.9%\tKNN: 85.9%\n",
      "\n",
      "id: 53\n",
      "name: Iris \t num_instances: 150 \t num_classes: 3 \t num_features: 4\n",
      "SVM: 100.0%\tSOM: 83.3%\tANN: 100.0%\tKMEANS: 90.0%\tKMEANS_RANDOM: 90.0%\tBIRCH: 86.7%\tRFC: 100.0%\tKNN: 96.7%\n",
      "\n",
      "id: 69\n",
      "name: Molecular Biology (Splice-junction Gene Sequences) \t num_instances: 3190 \t num_classes: 3 \t num_features: 287\n",
      "SVM: 95.8%\tSOM: 84.5%\tANN: 94.5%\tKMEANS: 76.7%\tKMEANS_RANDOM: 83.4%\tBIRCH: 61.0%\tRFC: 95.7%\tKNN: 81.0%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 82.1%\n",
      "Average accuracy RFC: 83.9%\n",
      "Average accuracy KNN: 79.4%\n",
      "Average accuracy ANN: 80.5%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 71.2%\n",
      "Average accuracy KMEANS: 68.9%\n",
      "Average accuracy KMEANS_RANDOM: 68.9%\n",
      "Average accuracy BIRCH: 68.5%\n",
      "\n",
      "id: 70\n",
      "name: MONK's Problems \t num_instances: 432 \t num_classes: 2 \t num_features: 6\n",
      "SVM: 79.3%\tSOM: 57.0%\tANN: 98.8%\tKMEANS: 48.3%\tKMEANS_RANDOM: 46.0%\tBIRCH: 48.3%\tRFC: 94.5%\tKNN: 81.6%\n",
      "\n",
      "id: 74\n",
      "name: Musk (Version 1) \t num_instances: 476 \t num_classes: 2 \t num_features: 734\n",
      "SVM: 93.8%\tSOM: 62.5%\tANN: 85.7%\tKMEANS: 61.0%\tKMEANS_RANDOM: 61.5%\tBIRCH: 61.5%\tRFC: 90.8%\tKNN: 85.4%\n",
      "\n",
      "id: 78\n",
      "name: Page Blocks Classification \t num_instances: 5473 \t num_classes: 5 \t num_features: 10\n",
      "SVM: 96.4%\tSOM: 90.7%\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\Documents\\D7041E\\Project\\ANN.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  1 / (1 + np.exp(-X)), # For positive values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN: 96.7%\tKMEANS: 91.4%\tKMEANS_RANDOM: 91.2%\tBIRCH: 91.8%\tRFC: 96.9%\tKNN: 96.1%\n",
      "\n",
      "id: 83\n",
      "name: Primary Tumor \t num_instances: 339 \t num_classes: 22 \t num_features: 17\n",
      "SVM: 37.0%\tSOM: 18.5%\tANN: 38.1%\tKMEANS: 29.6%\tKMEANS_RANDOM: 29.6%\tBIRCH: 25.9%\tRFC: 34.8%\tKNN: 37.0%\n",
      "\n",
      "id: 90\n",
      "name: Soybean (Large) \t num_instances: 307 \t num_classes: 15 \t num_features: 35\n",
      "SVM: 85.2%\tSOM: 50.0%\tANN: 79.6%\tKMEANS: 57.8%\tKMEANS_RANDOM: 57.4%\tBIRCH: 70.4%\tRFC: 89.3%\tKNN: 81.5%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.4%\n",
      "Average accuracy RFC: 83.4%\n",
      "Average accuracy KNN: 78.8%\n",
      "Average accuracy ANN: 80.3%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.2%\n",
      "Average accuracy KMEANS: 66.7%\n",
      "Average accuracy KMEANS_RANDOM: 66.6%\n",
      "Average accuracy BIRCH: 66.7%\n",
      "\n",
      "id: 95\n",
      "name: SPECT Heart \t num_instances: 267 \t num_classes: 2 \t num_features: 22\n",
      "SVM: 74.1%\tSOM: 63.0%\tANN: 80.0%\tKMEANS: 72.2%\tKMEANS_RANDOM: 72.2%\tBIRCH: 72.2%\tRFC: 81.5%\tKNN: 85.2%\n",
      "\n",
      "id: 96\n",
      "name: SPECTF Heart \t num_instances: 267 \t num_classes: 2 \t num_features: 44\n",
      "SVM: 72.2%\tSOM: 61.1%\tANN: 76.0%\tKMEANS: 72.2%\tKMEANS_RANDOM: 72.2%\tBIRCH: 72.2%\tRFC: 75.2%\tKNN: 70.4%\n",
      "\n",
      "id: 101\n",
      "name: Tic-Tac-Toe Endgame \t num_instances: 958 \t num_classes: 2 \t num_features: 27\n",
      "SVM: 97.4%\tSOM: 71.9%\tANN: 96.8%\tKMEANS: 65.1%\tKMEANS_RANDOM: 65.1%\tBIRCH: 65.1%\tRFC: 94.4%\tKNN: 95.8%\n",
      "\n",
      "id: 107\n",
      "name: Waveform Database Generator (Version 1) \t num_instances: 5000 \t num_classes: 3 \t num_features: 21\n",
      "SVM: 85.6%\tSOM: 81.7%\tANN: 85.5%\tKMEANS: 51.5%\tKMEANS_RANDOM: 51.5%\tBIRCH: 53.8%\tRFC: 84.1%\tKNN: 81.9%\n",
      "\n",
      "id: 109\n",
      "name: Wine \t num_instances: 178 \t num_classes: 3 \t num_features: 13\n",
      "SVM: 97.2%\tSOM: 80.6%\tANN: 100.0%\tKMEANS: 94.4%\tKMEANS_RANDOM: 94.4%\tBIRCH: 91.7%\tRFC: 95.0%\tKNN: 94.4%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 82.0%\n",
      "Average accuracy RFC: 83.8%\n",
      "Average accuracy KNN: 79.9%\n",
      "Average accuracy ANN: 81.5%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.8%\n",
      "Average accuracy KMEANS: 67.4%\n",
      "Average accuracy KMEANS_RANDOM: 67.4%\n",
      "Average accuracy BIRCH: 67.4%\n",
      "\n",
      "id: 110\n",
      "name: Yeast \t num_instances: 1484 \t num_classes: 10 \t num_features: 8\n",
      "SVM: 60.9%\tSOM: 44.4%\tANN: 59.0%\tKMEANS: 52.9%\tKMEANS_RANDOM: 53.5%\tBIRCH: 47.5%\tRFC: 64.2%\tKNN: 58.2%\n",
      "\n",
      "id: 111\n",
      "name: Zoo \t num_instances: 101 \t num_classes: 7 \t num_features: 16\n",
      "SVM: 95.2%\tSOM: 67.6%\tANN: 85.0%\tKMEANS: 79.0%\tKMEANS_RANDOM: 66.7%\tBIRCH: 76.2%\tRFC: 95.2%\tKNN: 90.5%\n",
      "\n",
      "id: 143\n",
      "name: Statlog (Australian Credit Approval) \t num_instances: 690 \t num_classes: 2 \t num_features: 14\n",
      "SVM: 83.3%\tSOM: 76.8%\tANN: 85.0%\tKMEANS: 83.3%\tKMEANS_RANDOM: 83.3%\tBIRCH: 76.8%\tRFC: 85.9%\tKNN: 84.8%\n",
      "\n",
      "id: 144\n",
      "name: Statlog (German Credit Data) \t num_instances: 1000 \t num_classes: 2 \t num_features: 61\n",
      "SVM: 71.0%\tSOM: 63.5%\tANN: 73.5%\tKMEANS: 65.0%\tKMEANS_RANDOM: 65.0%\tBIRCH: 65.0%\tRFC: 75.0%\tKNN: 71.0%\n",
      "\n",
      "id: 145\n",
      "name: Statlog (Heart) \t num_instances: 270 \t num_classes: 2 \t num_features: 13\n",
      "SVM: 81.5%\tSOM: 85.2%\tANN: 82.0%\tKMEANS: 73.7%\tKMEANS_RANDOM: 77.8%\tBIRCH: 75.9%\tRFC: 84.8%\tKNN: 81.5%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.5%\n",
      "Average accuracy RFC: 83.4%\n",
      "Average accuracy KNN: 79.5%\n",
      "Average accuracy ANN: 80.9%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.6%\n",
      "Average accuracy KMEANS: 67.9%\n",
      "Average accuracy KMEANS_RANDOM: 67.6%\n",
      "Average accuracy BIRCH: 67.6%\n",
      "\n",
      "id: 147\n",
      "name: Statlog (Image Segmentation) \t num_instances: 2310 \t num_classes: 7 \t num_features: 19\n",
      "SVM: 96.1%\tSOM: 79.7%\tANN: 95.9%\tKMEANS: 66.8%\tKMEANS_RANDOM: 56.7%\tBIRCH: 62.6%\tRFC: 98.2%\tKNN: 96.3%\n",
      "\n",
      "id: 149\n",
      "name: Statlog (Vehicle Silhouettes) \t num_instances: 946 \t num_classes: 4 \t num_features: 18\n",
      "SVM: 76.9%\tSOM: 40.2%\tANN: 76.9%\tKMEANS: 32.3%\tKMEANS_RANDOM: 30.8%\tBIRCH: 37.9%\tRFC: 68.8%\tKNN: 60.4%\n",
      "\n",
      "id: 151\n",
      "name: Connectionist Bench (Sonar, Mines vs. Rocks) \t num_instances: 208 \t num_classes: 2 \t num_features: 60\n",
      "SVM: 78.6%\tSOM: 50.0%\tANN: 72.5%\tKMEANS: 53.3%\tKMEANS_RANDOM: 50.0%\tBIRCH: 50.0%\tRFC: 75.7%\tKNN: 78.6%\n",
      "\n",
      "id: 161\n",
      "name: Mammographic Mass \t num_instances: 961 \t num_classes: 2 \t num_features: 5\n",
      "SVM: 81.3%\tSOM: 79.5%\tANN: 80.6%\tKMEANS: 80.1%\tKMEANS_RANDOM: 80.1%\tBIRCH: 59.6%\tRFC: 83.0%\tKNN: 80.1%\n",
      "\n",
      "id: 174\n",
      "name: Parkinsons \t num_instances: 197 \t num_classes: 2 \t num_features: 20\n",
      "SVM: 87.2%\tSOM: 69.2%\tANN: 85.7%\tKMEANS: 82.1%\tKMEANS_RANDOM: 82.1%\tBIRCH: 82.1%\tRFC: 92.8%\tKNN: 89.7%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.8%\n",
      "Average accuracy RFC: 83.4%\n",
      "Average accuracy KNN: 79.7%\n",
      "Average accuracy ANN: 81.1%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.0%\n",
      "Average accuracy KMEANS: 67.3%\n",
      "Average accuracy KMEANS_RANDOM: 66.7%\n",
      "Average accuracy BIRCH: 66.4%\n",
      "\n",
      "id: 176\n",
      "name: Blood Transfusion Service Center \t num_instances: 748 \t num_classes: 2 \t num_features: 4\n",
      "SVM: 80.7%\tSOM: 78.0%\tANN: 79.6%\tKMEANS: 79.3%\tKMEANS_RANDOM: 79.3%\tBIRCH: 78.7%\tRFC: 80.3%\tKNN: 83.3%\n",
      "\n",
      "id: 186\n",
      "name: Wine Quality \t num_instances: 4898 \t num_classes: 7 \t num_features: 11\n",
      "SVM: 56.5%\tSOM: 45.7%\tANN: 55.8%\tKMEANS: 44.7%\tKMEANS_RANDOM: 43.8%\tBIRCH: 44.6%\tRFC: 63.8%\tKNN: 62.2%\n",
      "\n",
      "id: 212\n",
      "name: Vertebral Column \t num_instances: 310 \t num_classes: 3 \t num_features: 6\n",
      "SVM: 80.6%\tSOM: 71.0%\tANN: 81.7%\tKMEANS: 70.6%\tKMEANS_RANDOM: 69.4%\tBIRCH: 77.4%\tRFC: 79.7%\tKNN: 79.0%\n",
      "\n",
      "id: 225\n",
      "name: ILPD (Indian Liver Patient Dataset) \t num_instances: 583 \t num_classes: 2 \t num_features: 11\n",
      "SVM: 67.2%\tSOM: 68.1%\tANN: 65.2%\tKMEANS: 67.2%\tKMEANS_RANDOM: 67.2%\tBIRCH: 67.2%\tRFC: 67.9%\tKNN: 68.1%\n",
      "\n",
      "id: 244\n",
      "name: Fertility \t num_instances: 100 \t num_classes: 2 \t num_features: 9\n",
      "SVM: 90.0%\tSOM: 90.0%\tANN: 90.0%\tKMEANS: 90.0%\tKMEANS_RANDOM: 90.0%\tBIRCH: 90.0%\tRFC: 90.0%\tKNN: 90.0%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.1%\n",
      "Average accuracy RFC: 82.7%\n",
      "Average accuracy KNN: 79.4%\n",
      "Average accuracy ANN: 80.3%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.3%\n",
      "Average accuracy KMEANS: 67.6%\n",
      "Average accuracy KMEANS_RANDOM: 67.0%\n",
      "Average accuracy BIRCH: 67.0%\n",
      "\n",
      "id: 257\n",
      "name: User Knowledge Modeling \t num_instances: 403 \t num_classes: 5 \t num_features: 5\n",
      "SVM: 90.1%\tSOM: 61.7%\tANN: 89.6%\tKMEANS: 46.4%\tKMEANS_RANDOM: 46.9%\tBIRCH: 56.8%\tRFC: 87.2%\tKNN: 82.7%\n",
      "\n",
      "id: 267\n",
      "name: Banknote Authentication \t num_instances: 1372 \t num_classes: 2 \t num_features: 4\n",
      "SVM: 100.0%\tSOM: 81.5%\tANN: 100.0%\tKMEANS: 53.7%\tKMEANS_RANDOM: 53.8%\tBIRCH: 64.0%\tRFC: 99.6%\tKNN: 100.0%\n",
      "\n",
      "id: 277\n",
      "name: Thoracic Surgery Data \t num_instances: 470 \t num_classes: 2 \t num_features: 37\n",
      "SVM: 85.1%\tSOM: 86.2%\tANN: 85.7%\tKMEANS: 86.2%\tKMEANS_RANDOM: 86.2%\tBIRCH: 86.2%\tRFC: 85.5%\tKNN: 85.1%\n",
      "\n",
      "id: 292\n",
      "name: Wholesale customers \t num_instances: 440 \t num_classes: 3 \t num_features: 7\n",
      "SVM: 64.8%\tSOM: 60.2%\tANN: 63.8%\tKMEANS: 64.8%\tKMEANS_RANDOM: 64.8%\tBIRCH: 64.8%\tRFC: 64.8%\tKNN: 64.8%\n",
      "\n",
      "id: 329\n",
      "name: Diabetic Retinopathy Debrecen \t num_instances: 1151 \t num_classes: 2 \t num_features: 18\n",
      "SVM: 70.1%\tSOM: 55.0%\tANN: 72.6%\tKMEANS: 52.8%\tKMEANS_RANDOM: 52.8%\tBIRCH: 57.6%\tRFC: 68.9%\tKNN: 62.3%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.2%\n",
      "Average accuracy RFC: 82.5%\n",
      "Average accuracy KNN: 79.3%\n",
      "Average accuracy ANN: 80.5%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.3%\n",
      "Average accuracy KMEANS: 67.0%\n",
      "Average accuracy KMEANS_RANDOM: 66.4%\n",
      "Average accuracy BIRCH: 66.9%\n",
      "\n",
      "id: 336\n",
      "name: Chronic Kidney Disease \t num_instances: 400 \t num_classes: 3 \t num_features: 35\n",
      "SVM: 100.0%\tSOM: 95.1%\tANN: 100.0%\tKMEANS: 99.0%\tKMEANS_RANDOM: 100.0%\tBIRCH: 97.6%\tRFC: 100.0%\tKNN: 97.6%\n",
      "\n",
      "id: 342\n",
      "name: Mice Protein Expression \t num_instances: 1080 \t num_classes: 8 \t num_features: 83\n",
      "SVM: 100.0%\tSOM: 27.9%\tANN: 99.0%\tKMEANS: 37.5%\tKMEANS_RANDOM: 31.5%\tBIRCH: 55.0%\tRFC: 100.0%\tKNN: 95.5%\n",
      "\n",
      "id: 379\n",
      "name: Website Phishing \t num_instances: 1353 \t num_classes: 3 \t num_features: 9\n",
      "SVM: 86.3%\tSOM: 81.2%\tANN: 88.1%\tKMEANS: 75.2%\tKMEANS_RANDOM: 77.1%\tBIRCH: 68.6%\tRFC: 88.6%\tKNN: 86.0%\n",
      "\n",
      "id: 419\n",
      "name: Autistic Spectrum Disorder Screening Data for Children   \t num_instances: 292 \t num_classes: 2 \t num_features: 88\n",
      "SVM: 100.0%\tSOM: 86.2%\tANN: 100.0%\tKMEANS: 95.2%\tKMEANS_RANDOM: 91.4%\tBIRCH: 84.5%\tRFC: 100.0%\tKNN: 94.8%\n",
      "\n",
      "id: 426\n",
      "name: Autism Screening Adult \t num_instances: 704 \t num_classes: 2 \t num_features: 104\n",
      "SVM: 100.0%\tSOM: 94.3%\tANN: 99.3%\tKMEANS: 92.3%\tKMEANS_RANDOM: 92.9%\tBIRCH: 87.2%\tRFC: 100.0%\tKNN: 97.9%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 82.6%\n",
      "Average accuracy RFC: 83.9%\n",
      "Average accuracy KNN: 80.7%\n",
      "Average accuracy ANN: 82.0%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 69.1%\n",
      "Average accuracy KMEANS: 68.1%\n",
      "Average accuracy KMEANS_RANDOM: 67.5%\n",
      "Average accuracy BIRCH: 67.9%\n",
      "\n",
      "id: 445\n",
      "name: Absenteeism at work \t num_instances: 740 \t num_classes: 121 \t num_features: 19\n",
      "SVM: 42.6%\tSOM: 31.1%\tANN: 43.5%\tKMEANS: 33.8%\tKMEANS_RANDOM: 30.4%\tBIRCH: 33.8%\tRFC: 48.0%\tKNN: 34.5%\n",
      "\n",
      "id: 451\n",
      "name: Breast Cancer Coimbra \t num_instances: 116 \t num_classes: 2 \t num_features: 9\n",
      "SVM: 70.8%\tSOM: 58.3%\tANN: 75.0%\tKMEANS: 57.5%\tKMEANS_RANDOM: 54.2%\tBIRCH: 58.3%\tRFC: 75.0%\tKNN: 75.0%\n",
      "\n",
      "id: 503\n",
      "name: Hepatitis C Virus (HCV) for Egyptian patients \t num_instances: 1385 \t num_classes: 4 \t num_features: 28\n",
      "SVM: 27.1%\tSOM: 23.5%\tANN: 27.0%\tKMEANS: 24.5%\tKMEANS_RANDOM: 23.8%\tBIRCH: 20.9%\tRFC: 26.4%\tKNN: 24.9%\n",
      "\n",
      "id: 519\n",
      "name: Heart Failure Clinical Records \t num_instances: 299 \t num_classes: 2 \t num_features: 12\n",
      "SVM: 81.7%\tSOM: 71.7%\tANN: 82.1%\tKMEANS: 70.0%\tKMEANS_RANDOM: 70.0%\tBIRCH: 70.0%\tRFC: 86.0%\tKNN: 78.3%\n",
      "\n",
      "id: 529\n",
      "name: Early Stage Diabetes Risk Prediction \t num_instances: 520 \t num_classes: 2 \t num_features: 31\n",
      "SVM: 93.3%\tSOM: 89.4%\tANN: 91.8%\tKMEANS: 71.2%\tKMEANS_RANDOM: 72.1%\tBIRCH: 73.1%\tRFC: 97.1%\tKNN: 94.2%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.0%\n",
      "Average accuracy RFC: 82.5%\n",
      "Average accuracy KNN: 79.1%\n",
      "Average accuracy ANN: 80.5%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 67.9%\n",
      "Average accuracy KMEANS: 66.7%\n",
      "Average accuracy KMEANS_RANDOM: 66.1%\n",
      "Average accuracy BIRCH: 66.6%\n",
      "\n",
      "id: 544\n",
      "name: Estimation of Obesity Levels Based On Eating Habits and Physical Condition  \t num_instances: 2111 \t num_classes: 7 \t num_features: 31\n",
      "SVM: 94.3%\tSOM: 45.9%\tANN: 95.5%\tKMEANS: 39.3%\tKMEANS_RANDOM: 39.0%\tBIRCH: 47.3%\tRFC: 92.5%\tKNN: 81.8%\n",
      "\n",
      "id: 545\n",
      "name: Rice (Cammeo and Osmancik) \t num_instances: 3810 \t num_classes: 2 \t num_features: 7\n",
      "SVM: 91.5%\tSOM: 88.8%\tANN: 91.4%\tKMEANS: 91.7%\tKMEANS_RANDOM: 91.7%\tBIRCH: 89.4%\tRFC: 92.9%\tKNN: 92.3%\n",
      "\n",
      "id: 547\n",
      "name: Algerian Forest Fires \t num_instances: 244 \t num_classes: 9 \t num_features: 337\n",
      "SVM: 93.9%\tSOM: 67.3%\tANN: 93.9%\tKMEANS: 80.4%\tKMEANS_RANDOM: 79.6%\tBIRCH: 83.7%\tRFC: 95.5%\tKNN: 89.8%\n",
      "\n",
      "id: 563\n",
      "name: Iranian Churn \t num_instances: 3150 \t num_classes: 2 \t num_features: 13\n",
      "SVM: 91.1%\tSOM: 84.1%\tANN: 89.7%\tKMEANS: 84.1%\tKMEANS_RANDOM: 84.1%\tBIRCH: 84.1%\tRFC: 95.1%\tKNN: 93.8%\n",
      "\n",
      "id: 565\n",
      "name: Bone marrow transplant: children \t num_instances: 187 \t num_classes: 2 \t num_features: 40\n",
      "SVM: 89.7%\tSOM: 72.4%\tANN: 80.0%\tKMEANS: 79.3%\tKMEANS_RANDOM: 79.3%\tBIRCH: 79.3%\tRFC: 96.6%\tKNN: 79.3%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.9%\n",
      "Average accuracy RFC: 83.4%\n",
      "Average accuracy KNN: 79.7%\n",
      "Average accuracy ANN: 81.3%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.2%\n",
      "Average accuracy KMEANS: 67.4%\n",
      "Average accuracy KMEANS_RANDOM: 66.7%\n",
      "Average accuracy BIRCH: 67.3%\n",
      "\n",
      "id: 582\n",
      "name: Student Performance on an Entrance Examination \t num_instances: 666 \t num_classes: 4 \t num_features: 49\n",
      "SVM: 50.7%\tSOM: 32.1%\tANN: 52.3%\tKMEANS: 37.6%\tKMEANS_RANDOM: 33.6%\tBIRCH: 35.1%\tRFC: 49.3%\tKNN: 42.5%\n",
      "\n",
      "id: 697\n",
      "name: Predict Students' Dropout and Academic Success \t num_instances: 4424 \t num_classes: 3 \t num_features: 36\n",
      "SVM: 75.8%\tSOM: 66.9%\tANN: 77.1%\tKMEANS: 65.4%\tKMEANS_RANDOM: 65.4%\tBIRCH: 62.7%\tRFC: 78.7%\tKNN: 69.9%\n",
      "\n",
      "id: 732\n",
      "name: DARWIN \t num_instances: 174 \t num_classes: 2 \t num_features: 624\n",
      "SVM: 80.0%\tSOM: 80.0%\tANN: 80.0%\tKMEANS: 76.0%\tKMEANS_RANDOM: 74.3%\tBIRCH: 62.9%\tRFC: 82.9%\tKNN: 65.7%\n",
      "\n",
      "id: 759\n",
      "name: Glioma Grading Clinical and Mutation Features \t num_instances: 839 \t num_classes: 2 \t num_features: 26\n",
      "SVM: 84.5%\tSOM: 82.7%\tANN: 83.9%\tKMEANS: 70.4%\tKMEANS_RANDOM: 85.7%\tBIRCH: 54.2%\tRFC: 84.3%\tKNN: 82.1%\n",
      "\n",
      "id: 850\n",
      "name: Raisin \t num_instances: 900 \t num_classes: 2 \t num_features: 7\n",
      "SVM: 87.8%\tSOM: 88.9%\tANN: 88.3%\tKMEANS: 84.2%\tKMEANS_RANDOM: 85.0%\tBIRCH: 84.4%\tRFC: 86.7%\tKNN: 85.0%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.4%\n",
      "Average accuracy RFC: 82.9%\n",
      "Average accuracy KNN: 79.0%\n",
      "Average accuracy ANN: 80.9%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.4%\n",
      "Average accuracy KMEANS: 67.3%\n",
      "Average accuracy KMEANS_RANDOM: 66.9%\n",
      "Average accuracy BIRCH: 66.8%\n",
      "\n",
      "id: 857\n",
      "name: Risk Factor Prediction of Chronic Kidney Disease \t num_instances: 200 \t num_classes: 2 \t num_features: 131\n",
      "SVM: 100.0%\tSOM: 100.0%\tANN: 100.0%\tKMEANS: 75.0%\tKMEANS_RANDOM: 85.0%\tBIRCH: 100.0%\tRFC: 100.0%\tKNN: 100.0%\n",
      "\n",
      "id: 863\n",
      "name: Maternal Health Risk \t num_instances: 1013 \t num_classes: 3 \t num_features: 6\n",
      "SVM: 66.0%\tSOM: 63.5%\tANN: 64.0%\tKMEANS: 50.9%\tKMEANS_RANDOM: 49.3%\tBIRCH: 49.3%\tRFC: 80.3%\tKNN: 77.8%\n",
      "\n",
      "id: 878\n",
      "name: Cirrhosis Patient Survival Prediction \t num_instances: 418 \t num_classes: 3 \t num_features: 776\n",
      "SVM: 71.4%\tSOM: 69.8%\tANN: 69.8%\tKMEANS: 67.0%\tKMEANS_RANDOM: 71.4%\tBIRCH: 66.7%\tRFC: 71.1%\tKNN: 65.1%\n",
      "\n",
      "id: 887\n",
      "name: National Health and Nutrition Health Survey 2013-2014 (NHANES) Age Prediction Subset \t num_instances: 6287 \t num_classes: 2 \t num_features: 7\n",
      "SVM: 84.4%\tSOM: 84.0%\tANN: 84.4%\tKMEANS: 84.4%\tKMEANS_RANDOM: 84.4%\tBIRCH: 84.4%\tRFC: 84.6%\tKNN: 85.7%\n",
      "\n",
      "id: 915\n",
      "name: Differentiated Thyroid Cancer Recurrence \t num_instances: 383 \t num_classes: 2 \t num_features: 55\n",
      "SVM: 96.1%\tSOM: 83.1%\tANN: 94.8%\tKMEANS: 84.4%\tKMEANS_RANDOM: 84.4%\tBIRCH: 87.0%\tRFC: 95.1%\tKNN: 90.9%\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.6%\n",
      "Average accuracy RFC: 83.1%\n",
      "Average accuracy KNN: 79.3%\n",
      "Average accuracy ANN: 81.0%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 69.1%\n",
      "Average accuracy KMEANS: 67.7%\n",
      "Average accuracy KMEANS_RANDOM: 67.4%\n",
      "Average accuracy BIRCH: 67.5%\n",
      "\n",
      "id: 936\n",
      "name: National Poll on Healthy Aging (NPHA) \t num_instances: 714 \t num_classes: 3 \t num_features: 14\n",
      "SVM: 56.6%\tSOM: 45.5%\tANN: 54.3%\tKMEANS: 53.3%\tKMEANS_RANDOM: 52.4%\tBIRCH: 52.4%\tRFC: 55.2%\tKNN: 51.0%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---Supervised---\n",
      "Average accuracy SVM: 81.2%\n",
      "Average accuracy Random Forest Classifier: 82.7%\n",
      "Average accuracy KNN: 78.9%\n",
      "Average accuracy ANN: 80.7%\n",
      "---Unsupervised---\n",
      "Average accuracy SOM: 68.8%\n",
      "Average accuracy KMEANS: 67.5%\n",
      "Average accuracy KMEANS_RANDOM: 67.2%\n",
      "Average accuracy BIRCH: 67.3%\n"
     ]
    }
   ],
   "source": [
    "dataset_ids = [12, 14, 15, 16, 17, 19, 22, 27, 28, 30, 32, 33, 39, 42, 43, 44, 45, 50, 52, 53, 69, 70, 74, 78, 83, 90, 95, 96, 101, 107, 109, 110, 111, 143, 144, 145, 147, 149, 151, 161, 174, 176, 186, 212, 225, 244, 257, 267, 277, 292, 329, 336, 342, 379, 419, 426, 445, 451, 503, 519, 529, 544, 545, 547, 563, 565, 582, 697, 732, 759, 850, 857, 863, 878, 887, 915, 936]\n",
    "\n",
    "print(\"number of datasets:\",len(dataset_ids))\n",
    "print()\n",
    "\n",
    "sum_accuracy_SVM = 0\n",
    "sum_accuracy_SOM = 0\n",
    "sum_accuracy_ANN = 0\n",
    "sum_accuracy_KMEANS = 0\n",
    "sum_accuracy_KMEANS_RANDOM = 0\n",
    "sum_accuracy_BIRCH = 0\n",
    "sum_accuracy_RFC = 0\n",
    "sum_accuracy_KNN = 0\n",
    "\n",
    "results_accuracy = {}\n",
    "seeds = [1234,2345,3456,4567,5678]\n",
    "for i, id in enumerate(dataset_ids):\n",
    "    \n",
    "    np.random.seed(seeds[0])\n",
    "    random.seed(seeds[0])\n",
    "    print(\"id:\",id)\n",
    "    ds = GenericDataset(id, splits=(0.5, 0.3, 0.2), show_info=False)\n",
    "    print(\"name:\",ds.get_metadata()['name'],\"\\t\",\"num_instances:\",ds.get_metadata()['num_instances'],\"\\t\",\"num_classes:\",ds.get_metadata()['num_classes'],\"\\t\",\"num_features:\",ds.get_metadata()['num_features'])\n",
    "\n",
    "    dataset_dict = {}\n",
    "    \n",
    "    accuracy, best_params, best_time = validate(ds,run_svm_on_ds,seeds, display_bar=False,**{'kernel':['rbf','poly','linear']})\n",
    "    sum_accuracy_SVM += accuracy\n",
    "    dataset_dict['SVM'] = [accuracy, best_params, best_time]\n",
    "    print(\"SVM:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_som_on_ds,seeds, display_bar=False,**{'ndim':[8,16],'nepochs':[25]})\n",
    "    sum_accuracy_SOM += accuracy\n",
    "    dataset_dict['SOM'] = [accuracy, best_params, best_time]\n",
    "    print(\"SOM:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_ann_on_ds,seeds, display_bar=False,**{'nepochs':[40],'batch_size':[7,10],'learning_rate':[0.05,0.10],'layer_configuration':[[100,100],[50]]})\n",
    "    sum_accuracy_ANN += accuracy\n",
    "    dataset_dict['ANN'] = [accuracy, best_params, best_time]\n",
    "    print(\"ANN:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_kmeans_on_ds,seeds, display_bar=False)\n",
    "    sum_accuracy_KMEANS += accuracy\n",
    "    dataset_dict['KMEANS'] = [accuracy, best_params, best_time]\n",
    "    print(\"KMEANS:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_kmeans_random_on_ds,seeds, display_bar=False)\n",
    "    sum_accuracy_KMEANS_RANDOM += accuracy\n",
    "    dataset_dict['KMEANS_RANDOM'] = [accuracy, best_params, best_time]\n",
    "    print(\"KMEANS_RANDOM:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_birch_on_ds,seeds, display_bar=False,**{'branching_factor':[25,50,75], 'threshold':[0.25,0.5,0.75]})\n",
    "    sum_accuracy_BIRCH += accuracy\n",
    "    dataset_dict['BIRCH'] = [accuracy, best_params, best_time]\n",
    "    print(\"BIRCH:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_random_forest_on_ds,seeds, display_bar=False,**{'max_depth':[None,3,5,7,15],'n_estimators':[200,100,10]})\n",
    "    sum_accuracy_RFC += accuracy\n",
    "    dataset_dict['RFC'] = [accuracy, best_params, best_time]\n",
    "    print(\"RFC:\",str(round(accuracy*1000)/10) + \"%\", end=\"\\t\")\n",
    "\n",
    "    accuracy, best_params, best_time = validate(ds,run_knn_on_ds,seeds, display_bar=False,**{'n_neighbors':[3,5,7,11,17],'weights':['uniform','distance']})\n",
    "    sum_accuracy_KNN += accuracy\n",
    "    dataset_dict['KNN'] = [accuracy, best_params, best_time]\n",
    "    print(\"KNN:\",str(round(accuracy*1000)/10) + \"%\")\n",
    "\n",
    "    results_accuracy[ds.get_metadata()['name']] = dataset_dict\n",
    "    print()\n",
    "    avg_accuracy_SVM = sum_accuracy_SVM/(i+1)\n",
    "    avg_accuracy_SOM = sum_accuracy_SOM/(i+1)\n",
    "    avg_accuracy_ANN = sum_accuracy_ANN/(i+1)\n",
    "    avg_accuracy_KMEANS = sum_accuracy_KMEANS/(i+1)\n",
    "    avg_accuracy_KMEANS_RANDOM = sum_accuracy_KMEANS_RANDOM/(i+1)\n",
    "    avg_accuracy_BIRCH = sum_accuracy_BIRCH/(i+1)\n",
    "    avg_accuracy_RFC = sum_accuracy_RFC/(i+1)\n",
    "    avg_accuracy_KNN = sum_accuracy_KNN/(i+1)\n",
    "\n",
    "    if i%5==0:\n",
    "        print(\"---Supervised---\")\n",
    "        \n",
    "        print(\"Average accuracy SVM:\", str(round(avg_accuracy_SVM*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy RFC:\", str(round(avg_accuracy_RFC*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy KNN:\", str(round(avg_accuracy_KNN*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy ANN:\", str(round(avg_accuracy_ANN*1000)/10)+\"%\")\n",
    "    \n",
    "        print(\"---Unsupervised---\")\n",
    "    \n",
    "        print(\"Average accuracy SOM:\", str(round(avg_accuracy_SOM*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy KMEANS:\", str(round(avg_accuracy_KMEANS*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy KMEANS_RANDOM:\", str(round(avg_accuracy_KMEANS_RANDOM*1000)/10)+\"%\")\n",
    "        print(\"Average accuracy BIRCH:\", str(round(avg_accuracy_BIRCH*1000)/10)+\"%\")\n",
    "    \n",
    "        print()\n",
    "\n",
    "avg_accuracy_SVM = sum_accuracy_SVM/len(dataset_ids)\n",
    "avg_accuracy_SOM = sum_accuracy_SOM/len(dataset_ids)\n",
    "avg_accuracy_ANN = sum_accuracy_ANN/len(dataset_ids)\n",
    "avg_accuracy_KMEANS = sum_accuracy_KMEANS/len(dataset_ids)\n",
    "avg_accuracy_KMEANS_RANDOM = sum_accuracy_KMEANS_RANDOM/len(dataset_ids)\n",
    "avg_accuracy_BIRCH = sum_accuracy_BIRCH/len(dataset_ids)\n",
    "avg_accuracy_RFC = sum_accuracy_RFC/len(dataset_ids)\n",
    "avg_accuracy_KNN = sum_accuracy_KNN/len(dataset_ids)\n",
    "\n",
    "print(\"\\n\"*3)\n",
    "print(\"---Supervised---\")\n",
    "print(\"Average accuracy SVM:\", str(round(avg_accuracy_SVM*1000)/10)+\"%\")\n",
    "print(\"Average accuracy Random Forest Classifier:\", str(round(avg_accuracy_RFC*1000)/10)+\"%\")\n",
    "print(\"Average accuracy KNN:\", str(round(avg_accuracy_KNN*1000)/10)+\"%\")\n",
    "print(\"Average accuracy ANN:\", str(round(avg_accuracy_ANN*1000)/10)+\"%\")\n",
    "print(\"---Unsupervised---\")\n",
    "print(\"Average accuracy SOM:\", str(round(avg_accuracy_SOM*1000)/10)+\"%\")\n",
    "print(\"Average accuracy KMEANS:\", str(round(avg_accuracy_KMEANS*1000)/10)+\"%\")\n",
    "print(\"Average accuracy KMEANS_RANDOM:\", str(round(avg_accuracy_KMEANS_RANDOM*1000)/10)+\"%\")\n",
    "print(\"Average accuracy BIRCH:\", str(round(avg_accuracy_BIRCH*1000)/10)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM': 0.8124235137220487, 'SOM': 0.6882077838700866, 'ANN': 0.8068783755255902, 'KMEANS': 0.6746514312832327, 'KMEANS_RANDOM': 0.6722540107061312, 'BIRCH': 0.6731239221554253, 'RFC': 0.8273331976744414, 'KNN': 0.789264983736093}\n"
     ]
    }
   ],
   "source": [
    "keys = list(results_accuracy.keys())\n",
    "models = list(results_accuracy[keys[0]].keys())\n",
    "sums = dict([(model,0) for model in models])\n",
    "\n",
    "for key in keys:\n",
    "    for model in models:\n",
    "        sums[model] += results_accuracy[key][model][0]\n",
    "\n",
    "avg = dict([(model,sums[model]/len(results_accuracy)) for model in models])\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json \n",
    "  \n",
    "with open('result_'+datetime.datetime.now().strftime(\"%I_%M_%d_%m_%Y\")+'.json', 'w') as file: \n",
    "     file.write(json.dumps(results_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
